7/2/2023
[SETTINGS] Number of training examples (n): 5
[SETTINGS] Number of features (d): 3
[SETTINGS] N of iterations (t): 1000 
[SETTINGS] GD step size (default 0.001): 0.001
[WARNING] Data set successfully deployed
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:55: RuntimeWarning: overflow encountered in square
  return (1/y.size) * np.sum((hypothesis(theta, x) - y) ** 2)
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:64: RuntimeWarning: invalid value encountered in subtract
  theta = theta - alpha * d_squared_loss(theta, x, y)
[WARNING] Optimized parameters: [nan nan nan nan]
[WARNING] Cost history: [1829782980811427.2, 1.2239180204311181e+23, 8.186628366207565e+30, 5.4759291788829664e+38, 3.6627777676969033e+46, 2.449984383887049e+54, 1.6387626719337193e+62, 1.0961470255016755e+70, 7.331984808382113e+77, 4.904269224809746e+85, 3.280401863615331e+93, 2.1942181176296248e+101, 1.4676839448042283e+109, 9.817146912282057e+116, 6.566561815880912e+124, 4.3922877458255095e+132, 2.9379441149052616e+140, 1.9651525860321823e+148, 1.3144649916234027e+156, 8.792285273339168e+163, 5.8810452024518165e+171, 3.933754603954751e+179, 2.6312372633497007e+187, 1.7600003643032697e+195, 1.1772413402219131e+203, 7.874414126477298e+210, 5.267093136873437e+218, 3.5230900568484645e+226, 2.3565490919024113e+234, 1.5762650210292196e+242, 1.0543431601140334e+250, 7.052364192877942e+257, 4.717234633893555e+265, 3.155296859693813e+273, 2.1105370085388657e+281, 1.4117107399030698e+289, 9.442749428674482e+296, 6.3161322112527445e+304, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
n, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 3 43 2020
[WARNING] The expected value of y is: [nan]
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '56979' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples (n): 5
[SETTINGS] Number of features (d): 2
[SETTINGS] N of iterations (t): 1000
[SETTINGS] GD step size (default 0.001): 0.000001
[WARNING] Data set successfully deployed
[WARNING] Optimized parameters: [ 0.2812753   0.63221767 21.98394533]
[WARNING] Cost history: [3431166.3875945807, 3333233.7182917404, 3238118.533105168, 3145739.774130598, 3056018.7154676286, 2968878.896128891, 2884246.054879397, 2802048.0669505354, 2722214.8825747757, 2644678.467288708, 2569372.7439535414, 2496233.5364436465, 2425198.5149551607, 2356207.142888038, 2289200.625256286, 2224121.858582418, 2160915.38223342, 2099527.331156768, 2039905.3899762046, 1981998.7484081672, 1925758.057960867, 1871135.389879114, 1818084.1942990609, 1766559.260578041, 1716516.6787657053, 1667913.8021836192, 1620709.2110814273, 1574862.67733862, 1530335.1301818106, 1487088.6228883194, 1445086.300447677, 
1404292.3681534973, 1364672.0610989456, 1326191.614549816, 1288818.2351699574, 1252520.0730745352, 1217266.194687314, 1183026.5563788167, 1149771.97886291, 1117474.1223299885, 1086105.462295566, 1055639.2661436948, 1026049.5703452204, 997311.1583314583, 969399.5390044375, 942290.9258653937, 915962.2167437291, 890390.9741091626, 865555.4059502883, 841434.3472032547, 818007.2417147312, 795254.1247237916, 773155.6058477899, 751692.8525577243, 730847.5741290067, 710602.0060539659, 690938.8949027939, 671841.4836200374, 653293.4972441054, 635279.1290376175, 617783.0270167793, 600790.2808683019, 584286.4092427151, 568257.3474132494, 552689.4352897637, 537569.4057775107, 522884.3734708144, 508621.8236720266, 494769.6017264034, 481315.90266381274, 468249.2611384471, 455558.54165796546, 443232.9290937395, 431261.9194641164, 419635.31098284293, 408343.19536502415, 397375.9493832043, 386724.22666637733, 376378.9497349367, 366331.3022647759, 356572.72157394764, 347094.89132547914, 337889.7344401253, 328949.40621301794, 320266.2876283467, 311832.9788663746, 303642.2929972528, 295687.2498562638, 287961.070095269, 280457.16940529685, 273169.1529053413, 266090.8096925951, 259216.10754946974, 252539.18780289215, 246054.36033149753, 239756.09871646363, 233639.03553185277, 227697.95777044987, 221927.80240119697, 216323.65205443805, 210880.73083129825, 205594.40023362497, 200460.15521102457, 195473.62032162206, 190630.54600327564, 185926.8049520661, 181358.38860497717, 176921.40372376522, 172612.06907711213, 168426.71221823047, 164361.76635517448, 160413.7673111933, 156579.35057253158, 152855.24842116443, 149238.2871500233, 145725.384358337, 142313.54632478638, 138999.86545623114, 135781.51780983582, 132655.7606864847, 129619.93029343095, 126671.43947419236, 123807.77550375565, 121026.49794721315, 118325.2365800049, 115701.68936799416, 113153.62050565652, 110678.8585107089, 108275.29437355472, 105940.87975996992, 103673.62526549668, 101471.59872005666, 99332.92354134086, 97255.77713557164, 95238.38934427395, 93279.04093573218, 91376.06213984746, 89527.83122514671, 87732.77311673042, 85989.35805398098, 84296.10028688944, 82651.55680988687, 81054.32613210427, 79503.04708301112, 77996.39765241473, 76533.09386383336, 75111.8886802806, 73731.57094153178, 72390.96433196259, 71088.92637808468, 69824.34747491995, 68596.14994038707, 67403.2870968923, 66244.74237934225, 65119.52846881954, 64026.68645118192, 62965.284999867705, 61934.419582212286, 60933.21168859838, 59960.80808378294, 59016.3800797637, 58099.12282956455, 57208.25464133879, 56343.016312205225, 55502.670481249224, 54686.50100113845, 53893.81232781585, 53123.9289277523, 52376.19470225111, 
51649.97242831578, 50944.64321560358, 50259.605979002146, 49594.276926380226, 48948.089061075494, 48320.491698695354, 47710.949997819655, 47118.94450420422, 
46543.970708098415, 45985.538614297606, 45443.172324565334, 44916.40963206955, 44404.80162748593, 43907.912316433816, 43425.31824791878, 42956.6081534639, 42501.38259662396, 42059.25363258213, 41629.84447754079, 41212.78918762329, 40807.73234701337, 40414.328765067585, 40032.24318214074, 39661.149983875075, 39300.732923709285, 38950.68485337053, 38610.707461120335, 38280.51101753118, 37959.81412857638, 37648.3434958244, 37345.83368353153, 37052.02689243529, 36766.67274005633, 36489.52804732, 36220.35663131768, 35958.92910402954, 35705.02267683856, 35458.42097066795, 35218.913831581696, 34986.29715168923, 34760.37269520331, 34540.94792950207, 34327.83586105091, 34120.85487604547, 33919.828585638665, 33724.585675620736, 33534.959760424164, 33350.78924132839, 33171.91716874405, 32998.19110845957, 32829.46301173532, 32665.589089135392, 32506.429687989097, 32351.849173377905, 32201.715812546274, 32055.901662637934, 31914.282461662027, 31776.737522596064, 31643.14963053545, 31513.404942802168, 31387.392891926855, 31265.00609142269, 31146.140244269598, 31030.6940540315, 30918.569138530802, 30809.66994600615, 30703.903673682795, 30601.18018868486, 30501.41195122392, 30404.51393999653, 30310.403579728638, 30219.000670804067, 30130.227320917926, 
30044.007878696233, 29960.268869225023, 29878.93893143456, 29799.948757284976, 29723.231032701195, 29648.720380207582, 29576.353303212523, 29506.068131896376, 29437.804970655703, 29371.505647059927, 29307.113662276373, 29244.574142921403, 29183.83379429691, 29124.84085497217, 29067.545052672504, 29011.897561436537, 28957.850960006574, 28905.3591914157, 28854.37752373782, 28804.86251196663, 28756.77196099147, 28710.064889638365, 28664.70149574546, 28620.64312224339, 28577.85222421145, 28536.292336881383, 28495.928044561926, 28456.72495045728, 28418.649647353814, 28381.669689150254, 28345.753563206905, 28310.870663490114, 
28276.991264489796, 28244.086495887095, 28212.128317950708, 28181.089497641395, 28150.94358540365, 28121.664892625224, 28093.22846974511, 28065.61008499131, 
28038.786203730313, 28012.733968410706, 27987.43117908381, 27962.8562744847, 27938.98831365745, 27915.80695810927, 27893.29245447769, 27871.425617696674, 27850.187814647, 27829.56094827686, 27809.52744217951, 27790.070225614516, 27771.172718959817, 27752.818819582557, 27734.992888116256, 27717.67973513285, 27700.864608198102, 27684.533179299528, 27668.671532635723, 27653.266152757613, 27638.303913050153, 27623.772064545752, 27609.658225059702, 27595.950368637732, 27582.636815307716, 27569.706221125463, 27557.14756850773, 27544.950156842755, 27533.10359337114, 27521.59778432904, 27510.422926346255, 27499.56949809164, 27489.028252159027, 27478.79020718635, 27468.846640201922, 27459.189079190444, 27449.809295873096, 27440.699298695516, 27431.85132601706, 27423.257839496495, 27414.91151766769, 27406.805249700166, 27398.932129339235, 27391.285449020448, 27383.858694153263, 27376.64553756948, 27369.63983413089, 27362.835615492513, 27356.22708501632, 27349.808612831228, 27343.57473103538, 27337.52012903629, 27331.639649025008, 27325.928281580844, 27320.381161402114, 27314.993563159853, 27309.76089747109, 27304.678706987543, 27299.742662597, 27294.948559734163, 27290.292314797403, 27285.76996166873, 27281.377648333688, 27277.111633598906, 27272.968283903567, 27268.944070222988, 27265.035565061142, 27261.239439529687, 27257.552460511113, 27253.971487903364, 27250.493471943926, 27247.115450610792, 27243.834547098064, 27240.647967364435, 27237.55299775212, 27234.547002674153, 27231.6274223683, 27228.791770715816, 27226.037633122505, 27223.36266446115, 27220.76458707283, 27218.24118882607, 27215.790321231496, 27213.40989761092, 27211.097891319074, 27208.852334016483, 27206.67131399198, 27204.552974533606, 27202.49551234626, 27200.497176014964, 27198.55626451218, 27196.67112574833, 27194.840155163824, 27193.061794361474, 27191.33452977873, 27189.656891397506, 27188.02745149166, 27186.444823410115, 27184.907660395158, 27183.414654434906, 27181.96453514826, 27180.55606870265, 27179.18805676228, 27177.85933546709, 27176.56877444069, 27175.315275827325, 27174.097773356003, 27172.915231431893, 27171.766644254014, 27170.651034957657, 27169.567454782235, 27168.514982262644, 27167.492722443887, 27166.499806118594, 27165.535389085984, 27164.59865143275, 27163.688796834056, 27162.805051875093, 27161.946665391868, 27161.112907831048, 27160.303070628284, 27159.51646560436, 27158.752424378647, 27158.0102977997, 27157.289455391678, 27156.58928481751, 27155.909191356677, 27155.24859739857, 27154.606941950235, 27153.98368015828, 27153.378282844424, 27152.79023605474, 27152.219040621552, 27151.66421173794, 27151.125278544812, 27150.601783729446, 27150.09328313578, 27149.599345386057, 27149.119551512984, 27148.65349460284, 27148.20077944867, 27147.761022213428, 27147.333850102914, 27146.918901048095, 27146.515823396505, 27146.124275612525, 27145.743925986477, 27145.374452351814, 27145.01554181059, 27144.66689046673, 27144.32820316723, 27143.99919325048, 27143.67958230203, 27143.369099917294, 27143.067483471063, 27142.774477893872, 27142.489835454402, 27142.21331554852, 27141.94468449412, 27141.683715332132, 27141.43018763287, 27141.183887308493, 27140.944606430254, 27140.712143051496, 27140.486301035406, 27140.26688988812, 27140.053724596004, 27139.846625468323, 27139.64541798392, 27139.4499326426, 27139.260004820524, 27139.075474630117, 27138.896186783648, 27138.721990460974, 27138.55273918097, 27138.388290676725, 27138.228506774292, 27138.073253274953, 27137.922399840812, 27137.77581988372, 27137.633390457475, 27137.494992152933, 27137.36050899637, 27137.229828350464, 27137.10284081855, 27136.979440151263, 27136.859523155843, 27136.742989608483, 27136.62974216872, 27136.51968629655, 27136.412730171898, 27136.308784616194, 27136.20776301661, 27136.109581252123, 27136.01415762175, 27135.921412775126, 27135.831269644692, 27135.743653380126, 27135.6584912845, 27135.57571275235, 27135.495249209525, 27135.417034054717, 27135.341002602683, 27135.267092029204, 27135.195241317404, 27135.125391205904, 27135.05748413829, 27134.99146421392, 27134.473743377046, 27134.423852281972, 2713


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 2 73
[WARNING] The expected value of y is: [1606.37371946]
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57017' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 5
[SETTINGS] Number of features: 2
[SETTINGS] N of iterations (default: 1000): 1000
[SETTINGS] GD step size (default: 0.000001): 0.000001
[WARNING] Data set successfully deployed
[WARNING] Optimized parameters: [0.0395589  0.27793731 0.30336219]
[WARNING] Cost history: [504.5880024610949, 504.37609826601323, 504.1642873736544, 503.9525697429356, 503.7409453327926, 503.52941410217863, 503.3179760100655, 503.1066310154428, 502.8953790773183, 502.6842201547179, 502.4731542066853, 502.26218119228236, 502.05130107058926, 501.84051380070343, 501.62981934174115, 501.41921765283627, 501.2087086931406, 500.99829242182426, 500.7879687980748, 500.5777377810985, 500.36759933011894, 500.1575534043777, 499.9475999631349, 
499.73773896566803, 499.5279703712725, 499.318294139262, 499.10871022896794, 498.8992185997397, 498.6898192109443, 498.48051202196694, 498.271296992211, 498.0621740810968, 497.85314324806336, 497.6442044525671, 497.4353576540828, 497.22660281210256, 497.01793988613673, 496.80936883571286, 496.6008896203772, 496.3925021996929, 496.18420653324176, 495.9760025806229, 495.76789030145295, 495.55986965536727, 495.351940602018, 495.1441031010754, 494.9363571122278, 494.7287025951809, 494.52113950965827, 494.31366781540123, 494.10628747216873, 493.89899843973774, 493.6918006779022, 493.4846941464749, 493.2776788052852, 493.070754614181, 492.8639215330272, 492.657179521707, 492.45052854012056, 492.2439685481866, 492.0374995058405, 491.831121373036, 491.6248341097443, 491.4186376759538, 491.21253203167134, 491.0065171369206, 490.80059295174345, 490.5947594361987, 490.38901655036335, 490.18336425433165, 489.9778025082155, 489.7723312721446, 489.5669505062657, 489.3616601707437, 489.1564602257604, 488.95135063151565, 488.74633134822665, 488.54140233612793, 488.33656355547174, 488.13181496652817, 487.9271565295838, 487.72258820494375, 487.5181099529301, 487.3137217338823, 487.1094235081577, 486.9052152361309, 486.7010968781936, 486.4970683947556, 486.2931297462434, 486.0892808931016, 485.8855217957919, 485.6818524147932, 485.47827271060214, 485.274782643733, 485.0713821747165, 484.8680712641017, 484.6648498724545, 484.46171796035856, 484.25867548841427, 484.0557224172401, 483.85285870747134, 483.6500843197609, 483.4473992147789, 483.2448033532127, 483.042296695767, 482.83987920316406, 482.6375508361432, 482.4353115554608, 482.23316132189103, 482.0311000962251, 481.8291278392712, 481.6272445118552, 481.4254500748202, 481.22374448902633, 481.02212771535073, 480.82059971468846, 480.6191604479512, 480.417809876068, 480.2165479599854, 480.0153746606665, 479.8142899390923, 479.6132937562606, 479.4123860731863, 479.21156685090176, 479.01083605045625, 478.81019363291625, 478.6096395593655, 478.4091737909046, 478.2087962886518, 478.00850701374185, 477.80830592732684, 477.6081929905763, 477.40816816467645, 477.2082314108306, 477.00838269025957, 476.8086219642007, 476.6089491939086, 
476.4093643406554, 476.20986736572945, 476.0104582304366, 475.8111368960999, 475.61190332405926, 475.41275747567164, 475.21369931231067, 475.01472879536755, 
474.81584588625003, 474.6170505463831, 474.4183427372089, 474.21972242018603, 474.02118955679043, 473.822744108515, 473.62438603686934, 473.42611530338047, 473.2279318695919, 473.02983569706413, 472.83182674737486, 472.6339049821185, 472.43607036290626, 472.2383228513667, 472.04066240914455, 471.8430889979022, 471.64560257931845, 471.44820311508914, 471.2508905669269, 471.0536648965612, 470.8565260657384, 470.659474036222, 470.4625087697916, 470.2656302282444, 470.0688383733941, 469.87213316707096, 469.6755145711226, 469.47898254741307, 469.2825370578232, 469.08617806425065, 468.88990552861, 468.6937194128325, 468.497619678866, 468.30160628867543, 468.1056792042423, 467.90983838756483, 467.714083800658, 467.51841540555347, 467.3228331642997, 467.12733703896185, 466.93192699162165, 466.73660298437784, 466.5413649793454, 466.3462129386565, 466.1511468244595, 465.9561665989197, 465.7612722242191, 465.5664636625562, 465.37174087614613, 465.1771038272209, 464.98255247802894, 464.78808679083505, 464.5937067279213, 464.39941225158594, 464.20520332414367, 464.01107990792616, 463.81704196528153, 463.6230894585745, 463.42922235018625, 463.23544060251436, 463.0417441779735, 462.84813303899455, 462.65460714802487, 462.4611664675285, 462.26781095998587, 462.07454058789426, 461.881355313767, 461.68825510013414, 461.4952399095424, 461.3023097045548, 461.1094644477507, 460.9167041017264, 460.72402862909394, 460.5314379924828, 460.33893215453804, 460.14651107792145, 459.95417472531153, 459.761923059403, 459.56975604290676, 459.37767363855073, 459.1856758090785, 458.99376251725073, 458.8019337258441, 458.6101893976518, 458.4185294954834, 458.2269539821647, 458.03546282053804, 457.8440559734622, 457.6527334038122, 457.4614950744792, 457.27034094837103, 457.0792709884117, 456.88828515754153, 456.6973834187172, 456.5065657349117, 456.3158320691143, 456.1251823843307, 455.93461664358256, 455.7441348099082, 455.5537368463621, 455.3634227160146, 455.1731923819531, 454.98304580728046, 454.7929829551164, 454.6030037885965, 454.41310827087267, 454.2232963651131, 454.0335680345021, 453.8439232422403, 453.65436195154444, 453.4648841256476, 453.2754897277988, 453.08617872126365, 452.8969510693232, 452.7078067352757, 452.5187456824346, 452.3297678741301, 452.1408732737081, 451.9520618445313, 451.7633335499779, 451.57468835344247, 451.38612621833556, 451.19764710808414, 451.009250986131, 450.82093781593517, 450.63270756097154, 450.4445601847317, 450.2564956507223, 450.0685139224668, 449.880614963505, 449.6927987373918, 449.5050652076988, 449.31741433801363, 449.12984609193967, 448.9423604330965, 448.75495732511973, 448.56763673166097, 448.38039861638777, 448.1932429429837, 448.00616967514827, 447.81917877659725, 447.63227021106206, 447.4454439422902, 447.25869993404524, 447.0720381501064, 446.8854585542693, 446.69896111034507, 446.51254578216106, 446.3262125335604, 446.13996132840225, 445.9537921305615, 445.7677049039292, 445.58169961241214, 445.39577621993305, 445.20993469043043, 445.0241749878588, 444.83849707618856, 444.65290091940597, 444.4673864815129, 444.2819537265275, 444.0966026184833, 443.91133312143006, 
443.7261451994331, 443.54103881657375, 443.3560139369492, 443.171070524672, 442.9862085438711, 442.8014279586908, 442.61672873329155, 442.4321108318493, 442.24757421855577, 442.06311885761863, 441.87874471326126, 441.69445174972253, 441.5102399312577, 441.3261092221369, 441.1420595866466, 440.95809098908904, 440.7742033937817, 440.5903967650582, 440.4066710672676, 440.22302626477494, 440.0394623219607, 439.855979203221, 439.6725768729679, 439.48925529562894, 439.3060144356474, 439.12285425748206, 438.93977472560766, 438.7567758045144, 438.573857458708, 438.3910196527099, 438.2082623510573, 438.0255855183028, 437.8429891190148, 437.6604731177772, 437.47803747918954, 437.2956821678667, 437.1134071484396, 436.93121238555443, 436.74909784387285, 436.5670634880725, 436.385109282846, 436.20323519290196, 436.0214411829645, 435.83972721777303, 435.65809326208273, 435.47653928066416, 435.29506523830327, 435.11367109980165, 434.9323568299767, 434.7511223936609, 434.56996775570207, 434.3888928809642, 434.207897734326, 434.02698228068215, 433.8461464849424, 433.6653903120323, 433.48471372689255, 433.3041166944797, 433.1235991797653, 432.9431611477365, 432.7628025633958, 432.58252339176124, 432.40232359786614, 432.22220314675934, 432.04216200350487, 431.86220013318234, 431.6823175008867, 431.5025140717282, 431.3227898108324, 431.14314468334044, 430.9635786544086, 430.7840916892085, 430.60468375292726, 430.4253548107672, 430.246104827946, 430.0669337696966, 429.88784160126755, 429.708828287922, 429.5298937949393, 429.35103808761346, 429.17226113125383, 428.99356289118515, 428.8149433327477, 428.63640242129645, 428.45794012220216, 428.2795564008504, 428.10125122264236, 427.92302455299415, 427.7448763573373, 427.5668066011186, 427.3888152497998, 427.2109022688581, 427.0330676237858, 426.8553112800905, 426.6776332032948, 426.50003335893666, 426.32251171256894, 426.14506822976, 425.9677028760934, 425.7904156171675, 425.61320641859606, 425.43607524600776, 425.2590220650466, 425.08204684137183, 424.9051495406576, 424.72833012859314, 424.5515885708828, 424.3749248332465, 424.1983388814185, 424.0218306811487, 423.84540019820173, 423.66904739835763, 423.4927722474111, 423.3165747111725, 423.14045475546664, 422.96441234613377, 422.7884474490288, 422.612560030022, 422.4367500549988, 422.2610174898591, 422.08536230051834, 421.90978445290676, 421.73428391296943, 421.55886064666686, 421.383514619974, 421.2082457988814, 421.033054149394, 420.85793963753196, 420.68290222933047, 420.5079418908397, 
420.3330585881244, 420.15825228726476, 419.98352295435575, 419.8088705555069, 419.6342950568432, 419.4597964245044, 419.2853746246449, 419.11102962343415, 418.9367613870566, 418.76256988171144, 418.58845507361303, 418.41441692899025, 418.24045541408697, 418.066570495162, 417.89276213848893, 417.7190303103562, 417.5453749770672, 417.37179610493996, 417.1982936603076, 417.0248676095178, 416.8515179189333, 416.6782445549314, 416.5050474839045, 416.33192667225944, 416.1588820864181, 415.9859136928171, 415.813021457908, 415.64020534815666, 415.4674653300442, 415.29480137006624, 415.12221343473334, 414.9497014905705, 414.7772655041176, 414.60490544192953, 414.4326212705756, 414.2604129566398, 414.0882804667211, 413.9162237674328, 413.74424282540343, 413.5723376072756, 413.40050807970704, 413.2287542093701, 413.0570759629516, 412.8854733071534, 412.71394620869154, 412.5424946342971, 412.3711185507157, 412.19981792470753, 412.0285927230410.4909545288607, 410.3204817465148, 410.15008402400485, 409.9797613282806, 409.8095136263068, 409.6393408850


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 9 10
[WARNING] The expected value of y is: [5.5746166]
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57080' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 3
[SETTINGS] Number of features: 2
[SETTINGS] N of iterations (default: 1000): 
Exception in Tkinter callback
Traceback (most recent call last):
  File "C:\Users\aless\AppData\Local\Programs\Python\Python39\lib\tkinter\__init__.py", line 1892, in __call__
    return self.func(*args)
  File "C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py", line 103, in deploy
    run_model(dataset)
  File "C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py", line 25, in run_model
    alpha = float(input('[SETTINGS] GD step size (default: 0.000001): '))
ValueError: could not convert string to float: ''
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57091' '--' 'C:\Users\aless\Desktop\linear-regression-aleb*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 2
[SETTINGS] Number of features:
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57101' '--' 'C:\Users\aless\Desktop\linear-regression-aleb*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 2
[SETTINGS] Number of features: 2
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57110' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 4
[SETTINGS] Number of features: 2
[SETTINGS] N of iterations (default: 1000): 
Exception in Tkinter callback
Traceback (most recent call last):
  File "C:\Users\aless\AppData\Local\Programs\Python\Python39\lib\tkinter\__init__.py", line 1892, in __call__
    return self.func(*args)
  File "C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py", line 102, in deploy
    run_model(dataset)
  File "C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py", line 24, in run_model
    alpha = float(input('[SETTINGS] GD step size (default: 0.000001): '))
ValueError: could not convert string to float: ''
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57127' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 4
[SETTINGS] Number of features: 2
[SETTINGS] N of iterations (default: 1000): 
[SETTINGS] GD step size (default: 0.000001): 
[WARNING] Data set successfully deployed
[WARNING] Optimized parameters: [0.00199402 0.00199402 0.00199402]
[WARNING] Cost history: [0.9999880000360001, 0.9999760002159991, 0.9999640005399957, 0.9999520010079878, 0.9999400016199741, 0.9999280023759525, 0.9999160032759213, 0.9999040043198789, 0.9998920055078238, 0.9998800068397538, 0.9998680083156675, 0.9998560099355628, 0.9998440116994384, 0.9998320136072923, 0.999820015659123, 0.9998080178549287, 0.9997960201947075, 0.9997840226784579, 0.9997720253061779, 0.999760028077866, 0.9997480309935204, 0.9997360340531395, 0.9997240372567213, 0.9997120406042642, 0.9997000440957666, 0.9996880477312267, 0.9996760515106426, 0.999664055434013, 0.9996520595013357, 0.999640063712609, 0.9996280680678317, 0.9996160725670014, 0.9996040772101167, 0.999592081997176, 0.9995800869281772, 0.999568092003119, 0.9995560972219996, 0.9995441025848169, 0.9995321080915693, 0.9995201137422555, 0.9995081195368732, 0.9994961254754212, 0.9994841315578974, 0.9994721377843001, 0.9994601441546277, 0.9994481506688783, 0.9994361573270504, 0.9994241641291423, 0.9994121710751519, 0.999400178165078, 0.9993881853989184, 0.9993761927766716, 0.9993642002983357, 0.9993522079639092, 0.9993402157733904, 0.9993282237267773, 0.9993162318240685, 0.9993042400652619, 0.999292248450356, 0.9992802569793493, 0.9992682656522395, 0.9992562744690253, 0.999244283429705, 0.9992322925342765, 0.9992203017827385, 0.9992083111750891, 0.9991963207113265, 0.9991843303914489, 0.999172340215455, 0.9991603501833426, 0.9991483602951102, 0.999136370550756, 0.9991243809502783, 0.9991123914936755, 0.9991004021809455, 0.9990884130120868, 0.999076423987098, 0.9990644351059769, 0.9990524463687218, 0.9990404577753313, 0.9990284693258036, 0.9990164810201367, 0.9990044928583289, 0.9989925048403787, 0.9989805169662844, 0.9989685292360441, 0.9989565416496562, 0.9989445542071188, 0.9989325669084304, 0.9989205797535889, 0.9989085927425931, 0.998896605875441, 0.9988846191521308, 0.9988726325726608, 0.9988606461370293, 0.9988486598452346, 0.998836673697275, 0.9988246876931487, 0.9988127018328541, 0.9988007161163894, 0.9987887305437527, 0.9987767451149426, 0.9987647598299573, 0.9987527746887948, 0.9987407896914537, 0.9987288048379321, 0.9987168201282283, 0.9987048355623405, 0.9986928511402671, 0.9986808668620064, 0.9986688827275565, 0.9986568987369159, 0.9986449148900827, 0.9986329311870552, 0.9986209476278317, 0.9986089642124107, 0.99859698094079, 0.9985849978129683, 0.9985730148289436, 0.9985610319887142, 0.9985490492922784, 0.9985370667396348, 0.9985250843307814, 0.9985131020657161, 0.9985011199444378, 0.9984891379669445, 0.9984771561332345, 0.9984651744433061, 0.9984531928971575, 0.9984412114947872, 0.9984292302361931, 0.9984172491213738, 0.9984052681503272, 
0.998393287323052, 0.9983813066395464, 0.9983693260998084, 0.9983573457038364, 0.9983453654516289, 0.9983333853431839, 0.9983214053784998, 0.9983094255575748, 0.9982974458804071, 0.9982854663469954, 0.9982734869573376, 0.9982615077114317, 0.9982495286092767, 0.9982375496508703, 0.9982255708362112, 0.9982135921652971, 0.9982016136381269, 0.9981896352546986, 0.9981776570150105, 0.9981656789190606, 0.9981537009668475, 0.9981417231583694, 0.9981297454936247, 0.9981177679726114, 0.998105790595328, 0.9980938133617725, 0.9980818362719436, 0.9980698593258394, 0.9980578825234578, 0.9980459058647977, 0.998033929349857, 0.998021952978634, 0.998009976751127, 0.9979980006673344, 0.9979860247272543, 0.9979740489308851, 0.9979620732782248, 0.9979500977692723, 0.9979381224040252, 0.9979261471824822, 0.9979141721046413, 0.9979021971705009, 0.9978902223800593, 0.9978782477333148, 0.9978662732302657, 0.9978542988709102, 0.9978423246552465, 0.997830350583273, 0.9978183766549878, 0.9978064028703894, 0.997794429229476, 0.9977824557322459, 0.9977704823786971, 0.9977585091688284, 0.9977465361026376, 0.9977345631801232, 0.9977225904012836, 0.9977106177661168, 0.9976986452746213, 0.9976866729267951, 0.9976747007226366, 0.9976627286621442, 0.9976507567453162, 0.9976387849721506, 0.9976268133426461, 0.9976148418568004, 0.9976028705146124, 0.9975908993160799, 0.9975789282612013, 0.9975669573499751, 0.9975549865823993, 
0.9975430159584722, 0.9975310454781923, 0.9975190751415577, 0.9975071049485666, 0.9974951348992175, 0.9974831649935086, 0.997471195231438, 0.9974592256130042, 0.9974472561382055, 0.9974352868070399, 0.9974233176195058, 0.9974113485756015, 0.9973993796753255, 0.9973874109186759, 0.9973754423056508, 0.9973634738362486, 0.9973515055104677, 0.9973395373283062, 0.9973275692897624, 0.9973156013948347, 0.9973036336435214, 0.9972916660358206, 0.9972796985717307, 0.99726773125125, 0.9972557640743764, 0.9972437970411089, 0.997231830151445, 0.9972198634053836, 0.9972078968029228, 0.9971959303440604, 0.9971839640287954, 0.9971719978571256, 0.9971600318290497, 0.9971480659445653, 0.9971361002036715, 0.9971241346063658, 0.997112169152647, 0.9971002038425132, 0.9970882386759629, 0.9970762736529939, 0.9970643087736046, 0.9970523440377937, 0.9970403794455591, 0.9970284149968993, 0.9970164506918123, 0.9970044865302966, 0.9969925225123505, 0.9969805586379722, 0.9969685949071596, 0.9969566313199115, 0.9969446678762263, 0.9969327045761018, 0.9969207414195365, 0.9969087784065286, 0.9968968155370764, 0.9968848528111783, 0.9968728902288323, 0.9968609277900369, 0.9968489654947906, 0.9968370033430911, 0.9968250413349371, 0.9968130794703269, 0.9968011177492586, 0.9967891561717303, 0.9967771947377406, 0.9967652334472877, 0.99675327230037, 0.9967413112969854, 0.9967293504371325, 0.9967173897208097, 0.9967054291480149, 
0.9966934687187464, 0.9966815084330027, 0.9966695482907822, 0.9966575882920827, 0.9966456284369029, 0.996633668725241, 0.996621709157095, 0.9966097497324634, 0.9965977904513447, 0.9965858313137368, 0.9965738723196381, 0.996561913469047, 0.9965499547619615, 0.9965379961983801, 0.9965260377783011, 0.9965140795017227, 0.9965021213686432, 0.9964901633790608, 0.996478205532974, 0.9964662478303807, 0.9964542902712795, 0.9964423328556686, 0.9964303755835464, 0.9964184184549107, 0.9964064614697605, 0.9963945046280934, 0.996382547929908, 0.9963705913752028, 0.9963586349639757, 0.9963466786962248, 0.996334722571949, 0.9963227665911463, 0.9963108107538149, 0.996298855059953, 0.9962868995095588, 0.9962749441026312, 0.996262988839168, 0.9962510337191672, 0.9962390787426275, 0.9962271239095473, 0.9962151692199245, 0.9962032146737577, 0.996191260271045, 0.9961793060117846, 0.9961673518959748, 0.9961553979236141, 0.9961434440947008, 0.9961314904092327, 0.9961195368672086, 0.9961075834686265, 0.9960956302134846, 0.9960836771017815, 0.9960717241335154, 0.9960597713086844, 0.9960478186272869, 0.9960358660893209, 0.996023913694785, 0.9960119614436778, 0.9960000093359967, 0.9959880573717407, 0.9959761055509078, 0.9959641538734963, 0.9959522023395048, 0.9959402509489309, 0.9959282997017732, 0.9959163485980302, 0.9959043976377, 0.995892446820781, 0.9958804961472713, 0.9958685456171693, 0.9958565952304731, 0.9958446449871812, 0.9958326948872916, 0.9958207449308031, 0.9958087951177135, 0.9957968454480212, 0.9957848959217245, 0.9957729465388216, 0.995760997299311, 0.9957490482031908, 0.9957370992504594, 0.9957251504411149, 0.9957132017751557, 0.99570125325258, 0.9956893048733862, 0.9956773566375726, 0.9956654085451374, 0.9956534605960788, 0.9956415127903951, 0.9956295651280846, 0.9956176176091457, 0.9956056702335768, 0.9955937230013758, 0.9955817759125413, 0.9955698289670712, 0.9955578821649641, 0.9955459355062182, 0.9955339889908317, 0.9955220426188032, 0.9955100963901303, 0.9954981503048123, 0.9954862043628464, 0.9954742585642316, 0.9954623129089659, 0.9954503673970476, 0.9954384220284751, 0.9954264768032465, 0.9954145317213601, 0.9954025867828143, 0.9953906419876074, 0.9953786973357377, 0.9953667528272033, 0.9953548084620026, 0.9953428642401339, 0.9953309201615952, 0.9953189762263853, 0.9953070324345021, 0.995295088785944, 0.995283145280709, 0.9952712019187958, 0.9952592587002027, 0.9952473156249276, 0.995235372692969, 0.9952234299043251, 0.9952114872589942, 0.9951995447569748, 0.9951876023982649, 0.9951756601828629, 0.9951637181107671, 0.9951517761819756, 0.9951398343964869, 0.9951278927542991, 0.9951159512554107, 0.9951040098998197, 0.9950920686875249, 0.9950801276185238, 0.9950681866928153, 0.9950562459103975, 0.9950443052712686, 0.9950323647754268, 0.9950204244228708, 0.9950084842135983, 0.9949965441476081, 0.9949846042248982, 0.994972664445467, 0.9949607248093126, 0.9949487853164335, 0.9949368459668279, 0.9949249067604939, 0.9949129676974302, 0.9949010287776348, 0.9948890900011058, 0.9948771513678418, 0.994865212877841, 0.9948532745311017, 0.994841336327622, 0.9948293982674004, 0.9948174603504348, 0.9948055225767242, 0.9947935849462662, 0.9947816474590594, 0.9947697101151021, 0.9947577729143923, 0.9947458358569288, 0.9947338989427092, 0.9947219621717323, 
0.9947100255439962, 0.9946980890594993, 0.9946861527182398, 0.9946742165202159, 0.9946622804654258, 0.9946503445538681, 0.994638408785541, 0.9946264731604425, 0.9946145376785711, 0.9946026023399251, 0.9945906671445026, 0.9945787320923022, 0.9945667971833219, 0.9945548624175602, 0.9945429277950152, 0.9945309933156851, 0.9945190589795684, 0.9945071247866635, 0.9944951907369681, 0.9944832568304811, 0.9944713230672007, 0.9944593894471249, 0.994447455970252, 0.9944355226365804, 0.9944235894461084, 0.9944116563988344, 0.9943997234947564, 0.9943877907338727, 0.9943758581161819, 0.994363925641682, 0.9943519933103716, 0.9943400611222485, 0.9943281290773114, 0.9943161971755581, 0.9943042654169874, 0.9942923338015974, 0.9942804023293862, 0.9942684710003525, 0.994256539814494, 0.9942446087718096, 0.9942326778722972, 0.9942207471159549, 0.9942088165027816, 0.994196886032775, 0.9941849557059337, 0.9941730255222558, 0.9941610954817397, 0.99414537315590919, 0.994041802950099, 0.9940298744842493, 0.9


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 1 1
[WARNING] The expected value of y is: [0.00598205]
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57136' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 2
[SETTINGS] Number of features: 2
[SETTINGS] N of iterations (default: 1000): 5000
[SETTINGS] GD step size (default: 0.000001): 
[WARNING] Data set successfully deployed
[WARNING] Optimized parameters: [0.00985152 0.00985152 0.00985152]
[WARNING] Cost history: [0.9999880000360001, 0.9999760002159991, 0.9999640005399957, 0.9999520010079878, 0.9999400016199741, 0.9999280023759525, 0.9999160032759213, 0.9999040043198789, 0.9998920055078238, 0.9998800068397538, 0.9998680083156675, 0.9998560099355628, 0.9998440116994384, 0.9998320136072923, 0.999820015659123, 0.9998080178549287, 0.9997960201947075, 0.9997840226784579, 0.9997720253061779, 0.999760028077866, 0.9997480309935204, 0.9997360340531395, 0.9997240372567213, 0.9997120406042642, 0.9997000440957666, 0.9996880477312267, 0.9996760515106426, 0.999664055434013, 0.9996520595013357, 0.999640063712609, 0.9996280680678317, 0.9996160725670014, 0.9996040772101167, 0.999592081997176, 0.9995800869281772, 0.999568092003119, 0.9995560972219996, 0.9995441025848169, 0.9995321080915693, 0.9995201137422555, 0.9995081195368732, 0.9994961254754212, 0.9994841315578974, 0.9994721377843001, 0.9994601441546277, 0.9994481506688783, 0.9994361573270504, 0.9994241641291423, 0.9994121710751519, 0.999400178165078, 0.9993881853989184, 0.9993761927766716, 0.9993642002983357, 0.9993522079639092, 0.9993402157733904, 0.9993282237267773, 0.9993162318240685, 0.9993042400652619, 0.999292248450356, 0.9992802569793493, 0.9992682656522395, 0.9992562744690253, 0.999244283429705, 0.9992322925342765, 0.9992203017827385, 0.9992083111750891, 0.9991963207113265, 0.9991843303914489, 0.999172340215455, 0.9991603501833426, 0.9991483602951102, 0.999136370550756, 0.9991243809502783, 0.9991123914936755, 0.9991004021809455, 0.9990884130120868, 0.999076423987098, 0.9990644351059769, 0.9990524463687218, 0.9990404577753313, 0.9990284693258036, 0.9990164810201367, 0.9990044928583289, 0.9989925048403787, 0.9989805169662844, 0.9989685292360441, 0.9989565416496562, 0.9989445542071188, 0.9989325669084304, 0.9989205797535889, 0.9989085927425931, 0.998896605875441, 0.9988846191521308, 0.9988726325726608, 0.9988606461370293, 0.9988486598452346, 0.998836673697275, 0.9988246876931487, 0.9988127018328541, 0.9988007161163894, 0.9987887305437527, 0.9987767451149426, 0.9987647598299573, 0.9987527746887948, 0.9987407896914537, 0.9987288048379321, 0.9987168201282283, 0.9987048355623405, 0.9986928511402671, 0.9986808668620064, 0.9986688827275565, 0.9986568987369159, 0.9986449148900827, 0.9986329311870552, 0.9986209476278317, 0.9986089642124107, 0.99859698094079, 0.9985849978129683, 0.9985730148289436, 0.9985610319887142, 0.9985490492922784, 0.9985370667396348, 0.9985250843307814, 0.9985131020657161, 0.9985011199444378, 0.9984891379669445, 0.9984771561332345, 0.9984651744433061, 0.9984531928971575, 0.9984412114947872, 0.9984292302361931, 0.9984172491213738, 0.9984052681503272, 
0.998393287323052, 0.9983813066395464, 0.9983693260998084, 0.9983573457038364, 0.9983453654516289, 0.9983333853431839, 0.9983214053784998, 0.9983094255575748, 0.9982974458804071, 0.9982854663469954, 0.9982734869573376, 0.9982615077114317, 0.9982495286092767, 0.9982375496508703, 0.9982255708362112, 0.9982135921652971, 0.9982016136381269, 0.9981896352546986, 0.9981776570150105, 0.9981656789190606, 0.9981537009668475, 0.9981417231583694, 0.9981297454936247, 0.9981177679726114, 0.998105790595328, 0.9980938133617725, 0.9980818362719436, 0.9980698593258394, 0.9980578825234578, 0.9980459058647977, 0.998033929349857, 0.998021952978634, 0.998009976751127, 0.9979980006673344, 0.9979860247272543, 0.9979740489308851, 0.9979620732782248, 0.9979500977692723, 0.9979381224040252, 0.9979261471824822, 0.9979141721046413, 0.9979021971705009, 0.9978902223800593, 0.9978782477333148, 0.9978662732302657, 0.9978542988709102, 0.9978423246552465, 0.997830350583273, 0.9978183766549878, 0.9978064028703894, 0.997794429229476, 0.9977824557322459, 0.9977704823786971, 0.9977585091688284, 0.9977465361026376, 0.9977345631801232, 0.9977225904012836, 0.9977106177661168, 0.9976986452746213, 0.9976866729267951, 0.9976747007226366, 0.9976627286621442, 0.9976507567453162, 0.9976387849721506, 0.9976268133426461, 0.9976148418568004, 0.9976028705146124, 0.9975908993160799, 0.9975789282612013, 0.9975669573499751, 0.9975549865823993, 
0.9975430159584722, 0.9975310454781923, 0.9975190751415577, 0.9975071049485666, 0.9974951348992175, 0.9974831649935086, 0.997471195231438, 0.9974592256130042, 0.9974472561382055, 0.9974352868070399, 0.9974233176195058, 0.9974113485756015, 0.9973993796753255, 0.9973874109186759, 0.9973754423056508, 0.9973634738362486, 0.9973515055104677, 0.9973395373283062, 0.9973275692897624, 0.9973156013948347, 0.9973036336435214, 0.9972916660358206, 0.9972796985717307, 0.99726773125125, 0.9972557640743764, 0.9972437970411089, 0.997231830151445, 0.9972198634053836, 0.9972078968029228, 0.9971959303440604, 0.9971839640287954, 0.9971719978571256, 0.9971600318290497, 0.9971480659445653, 0.9971361002036715, 0.9971241346063658, 0.997112169152647, 0.9971002038425132, 0.9970882386759629, 0.9970762736529939, 0.9970643087736046, 0.9970523440377937, 0.9970403794455591, 0.9970284149968993, 0.9970164506918123, 0.9970044865302966, 0.9969925225123505, 0.9969805586379722, 0.9969685949071596, 0.9969566313199115, 0.9969446678762263, 0.9969327045761018, 0.9969207414195365, 0.9969087784065286, 0.9968968155370764, 0.9968848528111783, 0.9968728902288323, 0.9968609277900369, 0.9968489654947906, 0.9968370033430911, 0.9968250413349371, 0.9968130794703269, 0.9968011177492586, 0.9967891561717303, 0.9967771947377406, 0.9967652334472877, 0.99675327230037, 0.9967413112969854, 0.9967293504371325, 0.9967173897208097, 0.9967054291480149, 
0.9966934687187464, 0.9966815084330027, 0.9966695482907822, 0.9966575882920827, 0.9966456284369029, 0.996633668725241, 0.996621709157095, 0.9966097497324634, 0.9965977904513447, 0.9965858313137368, 0.9965738723196381, 0.996561913469047, 0.9965499547619615, 0.9965379961983801, 0.9965260377783011, 0.9965140795017227, 0.9965021213686432, 0.9964901633790608, 0.996478205532974, 0.9964662478303807, 0.9964542902712795, 0.9964423328556686, 0.9964303755835464, 0.9964184184549107, 0.9964064614697605, 0.9963945046280934, 0.996382547929908, 0.9963705913752028, 0.9963586349639757, 0.9963466786962248, 0.996334722571949, 0.9963227665911463, 0.9963108107538149, 0.996298855059953, 0.9962868995095588, 0.9962749441026312, 0.996262988839168, 0.9962510337191672, 0.9962390787426275, 0.9962271239095473, 0.9962151692199245, 0.9962032146737577, 0.996191260271045, 0.9961793060117846, 0.9961673518959748, 0.9961553979236141, 0.9961434440947008, 0.9961314904092327, 0.9961195368672086, 0.9961075834686265, 0.9960956302134846, 0.9960836771017815, 0.9960717241335154, 0.9960597713086844, 0.9960478186272869, 0.9960358660893209, 0.996023913694785, 0.9960119614436778, 0.9960000093359967, 0.9959880573717407, 0.9959761055509078, 0.9959641538734963, 0.9959522023395048, 0.9959402509489309, 0.9959282997017732, 0.9959163485980302, 0.9959043976377, 0.995892446820781, 0.9958804961472713, 0.9958685456171693, 0.9958565952304731, 0.9958446449871812, 0.9958326948872916, 0.9958207449308031, 0.9958087951177135, 0.9957968454480212, 0.9957848959217245, 0.9957729465388216, 0.995760997299311, 0.9957490482031908, 0.9957370992504594, 0.9957251504411149, 0.9957132017751557, 0.99570125325258, 0.9956893048733862, 0.9956773566375726, 0.9956654085451374, 0.9956534605960788, 0.9956415127903951, 0.9956295651280846, 0.9956176176091457, 0.9956056702335768, 0.9955937230013758, 0.9955817759125413, 0.9955698289670712, 0.9955578821649641, 0.9955459355062182, 0.9955339889908317, 0.9955220426188032, 0.9955100963901303, 0.9954981503048123, 0.9954862043628464, 0.9954742585642316, 0.9954623129089659, 0.9954503673970476, 0.9954384220284751, 0.9954264768032465, 0.9954145317213601, 0.9954025867828143, 0.9953906419876074, 0.9953786973357377, 0.9953667528272033, 0.9953548084620026, 0.9953428642401339, 0.9953309201615952, 0.9953189762263853, 0.9953070324345021, 0.995295088785944, 0.995283145280709, 0.9952712019187958, 0.9952592587002027, 0.9952473156249276, 0.995235372692969, 0.9952234299043251, 0.9952114872589942, 0.9951995447569748, 0.9951876023982649, 0.9951756601828629, 0.9951637181107671, 0.9951517761819756, 0.9951398343964869, 0.9951278927542991, 0.9951159512554107, 0.9951040098998197, 0.9950920686875249, 0.9950801276185238, 0.9950681866928153, 0.9950562459103975, 0.9950443052712686, 0.9950323647754268, 0.9950204244228708, 0.9950084842135983, 0.9949965441476081, 0.9949846042248982, 0.994972664445467, 0.9949607248093126, 0.9949487853164335, 0.9949368459668279, 0.9949249067604939, 0.9949129676974302, 0.9949010287776348, 0.9948890900011058, 0.9948771513678418, 0.994865212877841, 0.9948532745311017, 0.994841336327622, 0.9948293982674004, 0.9948174603504348, 0.9948055225767242, 0.9947935849462662, 0.9947816474590594, 0.9947697101151021, 0.9947577729143923, 0.9947458358569288, 0.9947338989427092, 0.9947219621717323, 
0.9947100255439962, 0.9946980890594993, 0.9946861527182398, 0.9946742165202159, 0.9946622804654258, 0.9946503445538681, 0.994638408785541, 0.9946264731604425, 0.9946145376785711, 0.9946026023399251, 0.9945906671445026, 0.9945787320923022, 0.9945667971833219, 0.9945548624175602, 0.9945429277950152, 0.9945309933156851, 0.9945190589795684, 0.9945071247866635, 0.9944951907369681, 0.9944832568304811, 0.9944713230672007, 0.9944593894471249, 0.994447455970252, 0.9944355226365804, 0.9944235894461084, 0.9944116563988344, 0.9943997234947564, 0.9943877907338727, 0.9943758581161819, 0.994363925641682, 0.9943519933103716, 0.9943400611222485, 0.9943281290773114, 0.9943161971755581, 0.9943042654169874, 0.9942923338015974, 0.9942804023293862, 0.9942684710003525, 0.994256539814494, 0.9942446087718096, 0.9942326778722972, 0.9942207471159549, 0.9942088165027816, 0.994196886032775, 0.9941849557059337, 0.9941730255222558, 0.9941610954817397, 0.9941491655843839, 0.9941372358301862, 0.9941253062191453, 0.994113376751259, 0.9941014474265261, 0.9940895182449447, 0.994077589206513, 0.9940656603112293, 0.9940537315590919, 0.994041802950099, 0.9940298744842493, 0.9940179461615406, 0.9940060179819712, 0.9939940899455397, 0.993982162052244, 0.9939702343020829, 0.9939583066950541, 0.9939463792311564, 0.9939344519103874, 0.9939225247327462, 0.9939105976982308, 0.9938986708068391, 0.9938867440585698, 0.9938748174534209, 0.993862890991391, 0.9938509646724782, 0.9938390384966809, 0.9938271124639971, 0.9938151865744252, 0.9938032608279638, 0.9937913352246107, 0.9937794097643645, 
0.9937674844472233, 0.9937555592731855, 0.9937436342422495, 0.9937317093544134, 0.9937197846096755, 0.993707860008034, 0.9936959355494875, 0.9936840112340338, 0.9936720870616718, 0.9936601630323992, 0.9936482391462146, 0.9936363154031161, 0.9936243918031022, 0.9936124683461711, 0.9936005450323209, 0.9935886218615503, 0.993576698833857, 0.9935647759492399, 0.9935528532076967, 0.9935409306092262, 0.9935290081538262, 0.9935170858414956, 0.9935051636722321, 0.9934932416460341, 0.9934813197629001, 0.9934693980228283, 0.9934574764258168, 0.9934455549718643, 0.9934336336609687, 0.9934217124931285, 0.9934097914683416, 0.9933978705866068, 0.9933859498479221, 0.9933740292522857, 0.9933621087996961, 0.9933501884901517, 0.9933382683236504, 0.9933263483001907, 0.9933144284197708, 0.993302508682389, 0.9932905890880438, 0.9932786696367331, 0.9932667503284556, 0.9932548311632093, 0.9932429121409925, 0.9932309932618035, 0.9932190745256406, 0.9932071559325023, 0.9931952374823865, 0.9931833191752918, 0.9931714010112163, 0.9931594829901584, 0.9931475651121161, 0.993135647377088, 0.9931237297850724, 0.9931118123360675, 0.9930998950300716, 0.9930879778670827, 0.9930760608470994, 0.9930641439701201, 0.9930522272361427, 0.9930403106451658, 0.9930283941971875, 
0.9930164778922062, 0.99300456173022, 0.9929926457112276, 0.9929807298352267, 0.9929688141022158, 0.9929568985121936, 0.992944983065158, 0.9929330677611072, 
0.9929211526000395, 0.9929092375819536, 0.9928973227068474, 0.9928854079747192, 0.9928734933855674, 0.9928615789393902, 0.9928496646361858, 0.9928377504759527, 0.9928258364586894, 0.9928139225843936, 0.9928020088530637, 0.9927900952646983, 0.9927781818192957, 0.9927662685168538, 0.9927543553573713, 0.9927424423408461, 0.9927305294672768, 0.9927186167366614, 0.9927067041489985, 0.9926947917042862, 0.9926828794025228, 0.9926709672437065, 0.9926590552278357, 0.992647143


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 1 1
[WARNING] The expected value of y is: [0.02955455]
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\pythonn\Python39\python.exe' 'c:\Users\aless\.vscode\ext\debugpy\adapter/../..\debugpy\launcher' '57153' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-st--' 'C:\Users\aless\Desktop\linear-regression-alebats229.py'
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 3
[SETTINGS] Number of features: 1
[SETTINGS] N of iterations (default: 1000): 1000
[SETTINGS] GD step size (default: 0.000001): 
[WARNING] Data set successfully deployed
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:61: RuntimeWarning: overflow encountered in square
  return (1/y.size) * np.sum((hypothesis(theta, x) - y) ** 2)
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:70: RuntimeWarning: invalid value encountered in subtract
  theta = theta - alpha * d_squared_loss(theta, x, y)
[WARNING] Optimized parameters: [nan nan]
[WARNING] Cost history: [5466184.937703209, 306717575.3024977, 17242526599.50094, 969343119251.249, 54494718684867.5, 3063594651561594.0, 1.7222975762296704e+17, 9.682445879661101e+18, 5.443296182173231e+20, 3.060122792847337e+22, 1.7203457599775643e+24, 9.671473121243574e+25, 5.437127495588836e+27, 3.0566548686728865e+29, 1.7183961556468547e+31, 9.660512797848023e+32, 5.430965799749182e+34, 3.0531908745688596e+36, 1.7164487607307487e+38, 9.649564895382292e+39, 5.42481108673192e+41, 3.049730806081453e+43, 1.7145035727253995e+45, 
9.63862939977021e+46, 5.4186633486236724e+48, 3.0462746587619104e+50, 1.7125605891297962e+52, 9.627706296951543e+53, 5.412522577520038e+55, 3.0428224281665172e+57, 1.7106198074457638e+59, 9.616795572882001e+60, 5.406388765525562e+62, 3.0393741098565904e+64, 1.708681225177953e+66, 9.60589721353318e+67, 5.400261904753744e+69, 3.0359296993984846e+71, 1.7067448398338505e+73, 9.595011204892626e+74, 5.394141987327022e+76, 3.0324891923635776e+78, 1.7048106489237645e+80, 9.584137532963735e+81, 5.388029005376762e+83, 3.029052584328261e+85, 1.7028786499608207e+87, 9.573276183765755e+88, 5.381922951043239e+90, 3.025619870873944e+92, 1.7009488404609684e+94, 9.562427143333801e+95, 5.375823816475643e+97, 3.022191047587043e+99, 1.6990212179429687e+101, 9.551590397718788e+102, 5.369731593832056e+104, 3.0187661100589693e+106, 1.697095779928397e+108, 9.540765932987475e+109, 5.363646275279456e+111, 3.015345053886143e+113, 1.695172523941636e+115, 9.529953735222368e+116, 5.357567852993687e+118, 3.0119278746699626e+120, 1.693251447509873e+122, 9.519153790521781e+123, 5.351496319159462e+125, 3.008514568016817e+127, 1.6913325481630983e+129, 9.508366084999755e+130, 5.34543166597036e+132, 3.005105129538076e+134, 1.689415823434105e+136, 9.497590604786104e+137, 5.339373885628794e+139, 3.001699554850078e+141, 1.6875012708584768e+143, 9.486827336026318e+144, 5.3333229703460215e+146, 2.9982978395741314e+148, 1.6855888879745925e+150, 9.47607626488161e+151, 5.327278912342127e+153, 2.9948999793365084e+155, 
1.6836786723236212e+157, 9.465337377528882e+158, 5.3212417038460094e+160, 2.9915059697684373e+162, 1.681770621449519e+164, 9.454610660160692e+165, 5.315211337095375e+167, 2.9881158065060975e+169, 1.6798647328990239e+171, 9.443896098985244e+172, 5.309187804336728e+174, 2.984729485190611e+176, 1.6779610042216524e+178, 9.433193680226369e+179, 5.303171097825352e+181, 2.9813470014680395e+183, 1.676059432969701e+185, 9.422503390123509e+186, 5.297161209825311e+188, 2.9779683509893793e+190, 1.6741600166982383e+192, 9.411825214931713e+193, 5.29115813260944e+195, 2.974593529410559e+197, 1.6722627529651061e+199, 9.401159140921603e+200, 5.285161858459333e+202, 2.971222532392428e+204, 1.670367639330909e+206, 9.390505154379343e+207, 5.2791723796653216e+209, 2.9678553556007536e+211, 1.6684746733590237e+213, 9.379863241606676e+214, 5.273189688526488e+216, 2.9644919947062152e+218, 1.6665838526155818e+220, 9.369233388920822e+221, 5.267213777350622e+223, 2.9611324453843933e+225, 1.6646951746694745e+227, 9.35861558265454e+228, 5.26124463845425e+230, 2.9577767033157756e+232, 1.6628086370923487e+234, 9.348009809156061e+235, 5.255282264162593e+237, 2.9544247641857433e+239, 1.6609242374586048e+241, 9.337416054789103e+242, 5.249326646809575e+244, 2.951076623684564e+246, 1.6590419733453883e+248, 9.326834305932823e+249, 5.243377778737812e+251, 2.947732277507398e+253, 1.657161842332595e+255, 9.31626454898182e+256, 5.237435652298587e+258, 2.944391721354269e+260, 1.6552838420028586e+262, 9.305706770346105e+263, 5.2315002598518594e+265, 2.941054950930089e+267, 1.6534079699415558e+269, 9.295160956451101e+270, 
5.225571593766237e+272, 2.9377219619446274e+274, 1.6515342237367986e+276, 9.284627093737612e+277, 5.219649646418996e+279, 2.934392750112522e+281, 1.6496626009794317e+283, 9.274105168661798e+284, 5.213734410196029e+286, 2.931067311153264e+288, 1.6477930992630315e+290, 9.263595167695177e+291, 5.207825877491869e+293, 2.9277456407911973e+295, 1.6459257161839016e+297, 9.253097077324614e+298, 5.201924040709673e+300, 2.92442773475551e+302, 1.644060449341067e+304, 9.242610884052241e+305, 5.196028892261188e+307, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, 
inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, 
inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 2032 432
Exception in Tkinter callback
Traceback (most recent call last):
  File "C:\Users\aless\AppData\Local\Programs\Python\Python39\lib\tkinter\__init__.py", line 1892, in __call__
  File "C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py", line 102, in deploy
    run_model(dataset)
  File "C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py", line 52, in run_model
    print(f"[WARNING] The expected value of y is: {hypothesis(theta, x)}")
  File "C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py", line 58, in hypothesis
    return np.dot(x, theta)
  File "<__array_function__ internals>", line 200, in dot
ValueError: shapes (1,3) and (2,) not aligned: 3 (dim 1) != 2 (dim 0)
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57164' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py'
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 3
[SETTINGS] Number of features: 1
[SETTINGS] N of iterations (default: 1000): 100
[SETTINGS] GD step size (default: 0.000001): 0.01
[WARNING] Data set successfully deployed
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:61: RuntimeWarning: overflow encountered in square
  return (1/y.size) * np.sum((hypothesis(theta, x) - y) ** 2)
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:70: RuntimeWarning: invalid value encountered in subtract
  theta = theta - alpha * d_squared_loss(theta, x, y)
[WARNING] Optimized parameters: [nan nan]
[WARNING] Cost history: [700778662040360.2, 5.060480584711924e+24, 3.6542870289558006e+34, 2.6388429846638365e+44, 1.905567965113933e+54, 1.3760535548237753e+64, 9.936792706472357e+73, 7.175581862004442e+83, 5.181649308714036e+93, 3.74178569415644e+103, 2.70202774190994e+113, 1.9511951017004678e+123, 1.4090019380070427e+133, 1.0174720403804945e+143, 7.34739481210616e+152, 5.305719310456582e+162, 3.831379437371268e+172, 2.7667254021864457e+182, 1.997914739646808e+192, 1.442739241033281e+202, 1.0418345069045614e+212, 7.523321671071346e+221, 5.432760058464513e+231, 3.923118423387089e+241, 2.832972190615978e+251, 2.0457530379300528e+261, 1.4772843538891445e+271, 1.0667803111043384e+281, 7.703460942802796e+290, 5.562842684625061e+300, inf, inf, inf, inf, inf, inf, inf, inf, inf, 
n, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 1500
[WARNING] The expected value of y is: [nan]
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57171' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 3
[SETTINGS] Number of features: 1
[SETTINGS] N of iterations (default: 1000): 5000
[SETTINGS] GD step size (default: 0.000001): 
[WARNING] Data set successfully deployed
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:61: RuntimeWarning: overflow encountered in square
  return (1/y.size) * np.sum((hypothesis(theta, x) - y) ** 2)
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:70: RuntimeWarning: invalid value encountered in subtract
  theta = theta - alpha * d_squared_loss(theta, x, y)
[WARNING] Optimized parameters: [nan nan]
[WARNING] Cost history: [5466184.937703209, 306717575.3024977, 17242526599.50094, 969343119251.249, 54494718684867.5, 3063594651561594.0, 1.7222975762296704e+17, 9.682445879661101e+18, 5.443296182173231e+20, 3.060122792847337e+22, 1.7203457599775643e+24, 9.671473121243574e+25, 5.437127495588836e+27, 3.0566548686728865e+29, 1.7183961556468547e+31, 9.660512797848023e+32, 5.430965799749182e+34, 3.0531908745688596e+36, 1.7164487607307487e+38, 9.649564895382292e+39, 5.42481108673192e+41, 3.049730806081453e+43, 1.7145035727253995e+45, 9.63862939977021e+46, 5.4186633486236724e+48, 3.0462746587619104e+50, 1.7125605891297962e+52, 9.627706296951543e+53, 5.412522577520038e+55, 3.0428224281665172e+57, 1.7106198074457638e+59, 9.616795572882001e+60, 5.406388765525562e+62, 3.0393741098565904e+64, 1.708681225177953e+66, 9.60589721353318e+67, 5.400261904753744e+69, 3.0359296993984846e+71, 1.7067448398338505e+73, 9.595011204892626e+74, 5.394141987327022e+76, 3.0324891923635776e+78, 1.7048106489237645e+80, 9.584137532963735e+81, 5.388029005376762e+83, 3.029052584328261e+85, 1.7028786499608207e+87, 9.573276183765755e+88, 5.381922951043239e+90, 3.025619870873944e+92, 1.7009488404609684e+94, 9.562427143333801e+95, 5.375823816475643e+97, 3.022191047587043e+99, 1.6990212179429687e+101, 9.551590397718788e+102, 5.369731593832056e+104, 3.0187661100589693e+106, 1.697095779928397e+108, 9.540765932987475e+109, 5.363646275279456e+111, 3.015345053886143e+113, 1.695172523941636e+115, 9.529953735222368e+116, 5.357567852993687e+118, 3.0119278746699626e+120, 1.693251447509873e+122, 9.519153790521781e+123, 5.351496319159462e+125, 3.008514568016817e+127, 1.6913325481630983e+129, 9.508366084999755e+130, 5.34543166597036e+132, 3.005105129538076e+134, 1.689415823434105e+136, 9.497590604786104e+137, 5.339373885628794e+139, 3.001699554850078e+141, 1.6875012708584768e+143, 9.486827336026318e+144, 5.3333229703460215e+146, 2.9982978395741314e+148, 1.6855888879745925e+150, 9.47607626488161e+151, 5.327278912342127e+153, 2.9948999793365084e+155, 1.6836786723236212e+157, 9.465337377528882e+158, 5.3212417038460094e+160, 2.9915059697684373e+162, 1.681770621449519e+164, 9.454610660160692e+165, 5.315211337095375e+167, 2.9881158065060975e+169, 1.6798647328990239e+171, 9.443896098985244e+172, 5.309187804336728e+174, 2.984729485190611e+176, 1.6779610042216524e+178, 9.433193680226369e+179, 5.303171097825352e+181, 2.9813470014680395e+183, 1.676059432969701e+185, 9.422503390123509e+186, 5.297161209825311e+188, 2.9779683509893793e+190, 1.6741600166982383e+192, 9.411825214931713e+193, 5.29115813260944e+195, 2.974593529410559e+197, 1.6722627529651061e+199, 9.401159140921603e+200, 5.285161858459333e+202, 2.971222532392428e+204, 1.670367639330909e+206, 9.390505154379343e+207, 5.2791723796653216e+209, 2.9678553556007536e+211, 1.6684746733590237e+213, 9.379863241606676e+214, 5.273189688526488e+216, 2.9644919947062152e+218, 1.6665838526155818e+220, 9.369233388920822e+221, 5.267213777350622e+223, 
2.9611324453843933e+225, 1.6646951746694745e+227, 9.35861558265454e+228, 5.26124463845425e+230, 2.9577767033157756e+232, 1.6628086370923487e+234, 9.348009809156061e+235, 5.255282264162593e+237, 2.9544247641857433e+239, 1.6609242374586048e+241, 9.337416054789103e+242, 5.249326646809575e+244, 2.951076623684564e+246, 1.6590419733453883e+248, 9.326834305932823e+249, 5.243377778737812e+251, 2.947732277507398e+253, 1.657161842332595e+255, 9.31626454898182e+256, 5.237435652298587e+258, 2.944391721354269e+260, 1.6552838420028586e+262, 9.305706770346105e+263, 5.2315002598518594e+265, 2.941054950930089e+267, 1.6534079699415558e+269, 9.295160956451101e+270, 5.225571593766237e+272, 2.9377219619446274e+274, 1.6515342237367986e+276, 9.284627093737612e+277, 5.219649646418996e+279, 2.934392750112522e+281, 1.6496626009794317e+283, 9.274105168661798e+284, 5.213734410196029e+286, 2.931067311153264e+288, 1.6477930992630315e+290, 9.263595167695177e+291, 5.207825877491869e+293, 2.9277456407911973e+295, 1.6459257161839016e+297, 9.253097077324614e+298, 5.201924040709673e+300, 2.92442773475551e+302, 1.644060449341067e+304, 9.242610884052241e+305, 5.196028892261188e+307, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, 
inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, n, nan, nan


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 3
[WARNING] The expected value of y is: [nan]
xtensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57182' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
In riga:1 car:4
+ 11 c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\P ...
+    ~~
Token 'c:' imprevisto nell'espressione o nell'istruzione.
    + CategoryInfo          : ParserError: (:) [], ParentContainsErrorRecordException
    + FullyQualifiedErrorId : UnexpectedToken
 
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57189' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 3
[SETTINGS] Number of features: 1
[SETTINGS] N of iterations (default: 1000): 
[SETTINGS] GD step size (default: 0.000001): 0.0000000000001
[WARNING] Data set successfully deployed
[WARNING] Optimized parameters: [6.41072363e-08 1.28372169e-04]
[WARNING] Cost history: [107574.50173260849, 107574.33679883066, 107574.17186533313, 107574.00693211591, 107573.84199917901, 107573.67706652243, 107573.51213414619, 107573.34720205024, 107573.1822702346, 107573.01733869927, 107572.85240744427, 107572.68747646957, 107572.5225457752, 107572.35761536114, 107572.19268522739, 107572.02775537393, 107571.86282580081, 107571.69789650795, 107571.53296749547, 107571.36803876325, 107571.20311031135, 107571.03818213978, 107570.87325424848, 107570.70832663753, 107570.54339930684, 107570.37847225649, 107570.21354548646, 107570.0486189967, 107569.88369278728, 107569.71876685812, 107569.55384120927, 107569.38891584074, 107569.22399075249, 107569.05906594459, 107568.89414141695, 107568.72921716965, 107568.56429320262, 107568.3993695159, 107568.23444610948, 107568.06952298337, 107567.90460013752, 107567.739677572, 107567.5747552868, 107567.40983328185, 107567.24491155724, 107567.07999011292, 107566.91506894885, 107566.75014806513, 107566.5852274617, 107566.42030713854, 107566.25538709569, 107566.09046733312, 107565.92554785087, 107565.76062864889, 107565.59570972717, 107565.43079108579, 107565.26587272472, 107565.10095464389, 107564.93603684337, 107564.77111932315, 107564.6062020832, 107564.44128512358, 
107564.27636844423, 107564.11145204515, 107563.94653592637, 107563.78162008787, 107563.61670452965, 107563.45178925176, 107563.28687425412, 107563.12195953677, 107562.9570450997, 107562.79213094292, 107562.62721706642, 107562.4623034702, 107562.29739015429, 107562.1324771186, 107561.96756436327, 107561.80265188818, 107561.63773969335, 107561.47282777885, 107561.30791614461, 107561.14300479065, 107560.97809371696, 107560.81318292355, 107560.64827241044, 107560.48336217758, 107560.31845222502, 107560.15354255273, 107559.98863316073, 107559.82372404897, 107559.6588152175, 107559.4939066663, 107559.32899839539, 107559.16409040472, 107558.99918269437, 107558.83427526426, 107558.66936811445, 107558.50446124488, 107558.33955465561, 107558.17464834663, 107558.00974231785, 107557.84483656939, 107557.67993110119, 107557.51502591328, 107557.35012100563, 107557.18521637822, 107557.0203120311, 107556.85540796426, 107556.69050417766, 107556.52560067132, 107556.36069744529, 107556.19579449948, 107556.03089183394, 107555.86598944869, 107555.7010873437, 107555.53618551897, 107555.3712839745, 107555.20638271027, 107555.04148172634, 107554.87658102265, 107554.7116805992, 107554.54678045605, 107554.38188059315, 107554.21698101051, 107554.05208170813, 107553.88718268597, 107553.72228394414, 107553.5573854825, 107553.39248730114, 107553.22758940005, 107553.06269177923, 107552.89779443864, 107552.73289737833, 107552.56800059824, 107552.40310409841, 107552.23820787885, 107552.07331193954, 107551.90841628048, 107551.74352090168, 107551.57862580311, 107551.41373098482, 
107551.24883644679, 107551.08394218897, 107550.91904821142, 107550.75415451413, 107550.58926109705, 107550.42436796027, 107550.25947510371, 107550.09458252741, 107549.92969023135, 107549.76479821553, 107549.59990647997, 107549.43501502465, 107549.27012384958, 107549.10523295475, 107548.94034234015, 107548.77545200581, 107548.61056195172, 107548.44567217786, 107548.28078268425, 107548.11589347088, 107547.95100453775, 107547.78611588485, 107547.62122751221, 107547.45633941982, 107547.29145160763, 107547.12656407572, 107546.96167682402, 107546.79678985257, 107546.63190316137, 107546.4670167504, 107546.30213061965, 107546.13724476915, 107545.9723591989, 107545.80747390885, 107545.64258889908, 107545.47770416948, 107545.31281972016, 107545.14793555108, 107544.98305166222, 107544.81816805358, 107544.65328472518, 107544.48840167701, 107544.32351890908, 107544.15863642139, 107543.99375421391, 107543.82887228667, 107543.66399063964, 107543.49910927286, 107543.3342281863, 107543.16934737997, 107543.00446685388, 107542.83958660801, 107542.67470664236, 107542.50982695693, 107542.34494755174, 107542.18006842678, 107542.01518958202, 107541.8503110175, 107541.68543273318, 107541.52055472913, 107541.35567700527, 107541.19079956163, 107541.02592239821, 
107540.86104551502, 107540.69616891207, 107540.5312925893, 107540.36641654676, 107540.20154078446, 107540.03666530237, 107539.8717901005, 107539.70691517886, 107539.5420405374, 107539.37716617621, 107539.21229209518, 107539.04741829439, 107538.88254477382, 107538.71767153346, 107538.5527985733, 107538.38792589337, 107538.22305349367, 107538.05818137417, 107537.89330953488, 107537.72843797578, 107537.56356669695, 107537.39869569827, 107537.23382497983, 107537.0689545416, 107536.90408438354, 107536.73921450574, 107536.57434490813, 107536.40947559074, 107536.24460655355, 107536.07973779656, 107535.91486931978, 107535.7500011232, 107535.58513320686, 107535.4202655707, 107535.25539821471, 107535.09053113897, 107534.92566434343, 107534.7607978281, 107534.59593159295, 107534.43106563803, 107534.26619996325, 107534.10133456875, 107533.9364694544, 107533.77160462028, 107533.60674006635, 107533.44187579263, 107533.27701179907, 107533.11214808574, 107532.94728465262, 107532.78242149968, 107532.61755862694, 107532.4526960344, 107532.28783372203, 107532.12297168991, 107531.95810993793, 107531.79324846616, 107531.62838727463, 107531.46352636322, 107531.29866573204, 107531.13380538105, 107530.96894531029, 107530.80408551966, 107530.63922600927, 107530.47436677905, 107530.30950782902, 107530.14464915918, 107529.97979076953, 107529.81493266005, 107529.6500748308, 107529.48521728173, 107529.32036001282, 107529.15550302413, 107528.9906463156, 107528.82578988724, 107528.66093373911, 107528.49607787114, 107528.33122228338, 107528.16636697577, 107528.00151194837, 107527.83665720114, 107527.6718027341, 107527.50694854722, 107527.34209464055, 107527.17724101405, 107527.01238766775, 107526.8475346016, 107526.68268181566, 107526.51782930989, 107526.3529770843, 107526.18812513888, 107526.02327347363, 107525.85842208857, 107525.69357098368, 107525.52872015898, 107525.36386961445, 107525.19901935011, 107525.03416936591, 107524.8693196619, 107524.70447023808, 107524.53962109443, 107524.37477223093, 107524.2099236476, 107524.0450753445, 107523.88022732153, 107523.71537957873, 107523.5505321161, 107523.38568493369, 107523.22083803138, 107523.05599140929, 107522.89114506732, 107522.72629900558, 107522.56145322396, 107522.3966077225, 107522.23176250125, 107522.06691756015, 107521.90207289919, 107521.73722851844, 107521.57238441783, 107521.4075405974, 107521.24269705711, 107521.07785379702, 107520.91301081705, 107520.74816811728, 107520.58332569765, 107520.41848355818, 107520.25364169889, 107520.08880011976, 107519.92395882077, 107519.75911780194, 107519.5942770633, 107519.4294366048, 107519.26459642645, 107519.09975652827, 107518.93491691025, 107518.77007757238, 107518.60523851468, 107518.44039973713, 107518.27556123972, 107518.11072302249, 107517.94588508541, 107517.78104742845, 107517.6162100517, 107517.45137295505, 107517.28653613858, 107517.12169960228, 107516.9568633461, 107516.79202737009, 107516.62719167423, 107516.46235625853, 107516.29752112293, 107516.13268626752, 107515.96785169226, 107515.80301739715, 107515.63818338218, 107515.47334964736, 107515.30851619269, 107515.14368301813, 107514.97885012379, 107514.81401750953, 107514.64918517548, 107514.4843531215, 107514.31952134773, 107514.15468985404, 107513.98985864055, 107513.82502770718, 107513.66019705395, 107513.49536668087, 107513.33053658794, 107513.16570677512, 107513.00087724248, 107512.83604798993, 107512.67121901756, 107512.50639032533, 107512.34156191321, 
107512.17673378125, 107512.01190592942, 107511.84707835776, 107511.68225106617, 107511.5174240548, 107511.3525973235, 107511.18777087233, 107511.02294470134, 107510.85811881047, 107510.69329319971, 107510.52846786911, 107510.36364281864, 107510.1988180483, 107510.0339935581, 107509.86916934804, 107509.70434541805, 107509.53952176825, 107509.37469839858, 107509.20987530902, 107509.04505249958, 107508.88022997028, 107508.71540772112, 107508.55058575206, 107508.38576406316, 107508.22094265437, 107508.05612152567, 107507.89130067716, 107507.72648010874, 107507.56165982047, 107507.39683981231, 107507.2320200843, 107507.06720063637, 107506.90238146858, 107506.7375625809, 107506.57274397336, 107506.40792564594, 107506.24310759862, 107506.07828983144, 107505.91347234437, 107505.74865513745, 107505.58383821062, 107505.4190215639, 107505.2542051973, 107505.08938911086, 107504.9245733045, 107504.75975777827, 107504.59494253215, 107504.43012756616, 107504.26531288025, 107504.10049847446, 107503.93568434883, 107503.77087050329, 107503.60605693785, 107503.44124365255, 107503.27643064733, 107503.11161792222, 107502.94680547723, 107502.78199331238, 107502.61718142762, 107502.45236982296, 107502.28755849844, 107502.122747454, 107501.9579366897, 107501.79312620548, 107501.62831600136, 107501.46350607737, 107501.29869643346, 107501.1338870697, 107500.969077986, 107500.80426918244, 107500.63946065896, 107500.4746524156, 107500.30984445236, 107500.14503676917, 107499.98022936613, 107499.81542224318, 107499.65061540036, 107499.48580883759, 107499.32100255496, 107499.1561965524, 107498.99139082996, 107498.82658538761, 107498.66178022535, 107498.49697534322, 107498.33217074117, 107498.16736641922, 107498.00256237738, 107497.83775861558, 107497.67295513395, 107497.50815193239, 107497.34334901092, 107497.17854636956, 107497.01374400826, 107496.84894192708, 107496.68414012599, 13.88255236125, 107493.71775560176, 107493.55295912235, 107493.38816292302, 107493.2233670038, 107493.05857136463, 107492.89377600557, 107492.72898092656, 107492.56418612765, 107492.39939160885, 1074

[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 1940
[WARNING] The expected value of y is: [0.24904207]
PS C:\Users\aless\Desktop>
PS C:\Users\aless\Desktop>
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57204' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 3
[SETTINGS] Number of features: 1
[SETTINGS] N of iterations (default: 1000): 1000
[SETTINGS] GD step size (default: 0.000001): 0.01
[WARNING] Data set successfully deployed
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:61: RuntimeWarning: overflow encountered in square
  return (1/y.size) * np.sum((hypothesis(theta, x) - y) ** 2)
C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py:70: RuntimeWarning: invalid value encountered in subtract
  theta = theta - alpha * d_squared_loss(theta, x, y)
[WARNING] Optimized parameters: [nan nan]
[WARNING] Cost history: [700778662040360.2, 5.060480584711924e+24, 3.6542870289558006e+34, 2.6388429846638365e+44, 1.905567965113933e+54, 1.3760535548237753e+64, 9.936792706472357e+73, 7.175581862004442e+83, 5.181649308714036e+93, 3.74178569415644e+103, 2.70202774190994e+113, 1.9511951017004678e+123, 1.4090019380070427e+133, 1.0174720403804945e+143, 7.34739481210616e+152, 5.305719310456582e+162, 3.831379437371268e+172, 2.7667254021864457e+182, 1.997914739646808e+192, 1.442739241033281e+202, 1.0418345069045614e+212, 7.523321671071346e+221, 5.432760058464513e+231, 3.923118423387089e+241, 2.832972190615978e+251, 2.0457530379300528e+261, 1.4772843538891445e+271, 1.0667803111043384e+281, 7.703460942802796e+290, 5.562842684625061e+300, inf, inf, inf, inf, inf, inf, inf, inf, inf, 
inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,an, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 
nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 2
PS C:\Users\aless\Desktop>  c:; cd 'c:\Users\aless\Desktop'; & 'C:\Users\aless\AppData\Local\Programs\Python\Python39\python.exe' 'c:\Users\aless\.vscode\extensions\ms-python.python-2023.10.1\pythonFiles\lib\python\debugpy\adapter/../..\debugpy\launcher' '57225' '--' 'C:\Users\aless\Desktop\linear-regression-alebarro-stats229.py' 
*---------------------------------------------------------------*

Linear regression ML model by @alebarro [Stanford CS229/STATS229]

*---------------------------------------------------------------*

[STATUS] Initialization
[SETTINGS] Number of training examples: 3
[SETTINGS] Number of features: 1
[SETTINGS] N of iterations (default: 1000): 5000
[SETTINGS] GD step size (default: 0.000001): 0.000000001
[WARNING] Data set successfully deployed
[WARNING] Optimized parameters: [0.00020409 0.15112784]
[WARNING] Cost history: [105932.33333580056, 104317.79410631492, 102730.57860349504, 101170.22441303376, 99636.27694631305, 98128.28930796568, 96645.822165678, 95188.44362219647, 93755.72908949992, 92347.26116510152, 90962.6295104441, 89601.43073135326, 88263.26826051404, 86947.752241936, 85654.49941737404, 84383.133014671, 83133.28263799017, 81904.5841599053, 80696.67961531687, 79509.21709716372, 78341.8506538995, 77194.24018870432, 76066.05136040197, 74956.95548605407, 73866.62944520259, 72794.75558573302, 71741.02163133054, 70705.12059050251, 69686.75066714048, 68685.61517259594, 67701.42243924392, 66733.88573550957, 
65782.72318233256, 64847.65767104547, 63928.41678264176, 63024.73270841011, 62136.342171911834, 61262.986352278866, 60404.410808809596, 59560.36540684101, 58730.604244875154, 57914.885582939154, 57112.97177215728, 56324.629185515165, 55549.62814979564, 54787.742878666475, 54038.75140690053, 53302.43552570902, 52578.58071916942, 51866.97610172893, 51167.41435676587, 50479.69167619056, 49803.6077010687, 49138.96546324932, 48485.57132798077, 47843.23493749769, 47211.76915556292, 46590.99001294776, 45980.7166538349, 45380.77128312856, 44790.9791146562, 44211.1683202469, 43641.16997967135, 43080.81803142939, 42529.94922437003, 41988.403070130356, 41456.021796379515, 40932.65030085369, 40418.136106169135, 39912.32931539993, 39415.08256840746, 38926.250998909, 38445.69219227281, 37973.26614402751, 37508.83521907368, 37052.264111585624, 36603.419805591795, 36162.17153622242, 35728.390751612795, 35301.95107545147, 34882.728270162115, 34470.60020070857, 34065.4467990124, 33667.15002897268, 33275.59385207768, 32890.664193598604, 32512.24890935542, 32140.23775304512, 31774.522344122946, 31414.9961362271, 31061.554386137916, 30714.09412326225, 30372.514119634405, 30036.71486042469, 29706.598514947036, 29382.068908157373, 29063.031492634276, 28749.39332103386, 28441.063019010704, 28137.95075859722, 27839.968232033458, 27547.028626039762, 27259.046596524877, 26975.93824372213, 26697.62108774623, 26424.01404456393, 26155.037402371272, 25890.612798370512, 25630.663195940248, 25375.112862191752, 25123.887345905256, 24876.913455839465, 24634.119239408392, 24395.433961718812, 24160.788084962613, 23930.113248157904, 23703.342247232915, 23480.409015446974, 23261.248604142853, 23045.79716382479, 22833.991925556886, 22625.771182676042, 22421.074272814676, 22219.84156022749, 22022.014418417355, 21827.535213055304, 21636.34728518949, 21448.394934738404, 21263.623404263297, 21081.97886301541, 20903.408391253062, 20727.85996482417, 20555.282440009716, 20385.62553862369, 20218.839833365208, 20054.876733418518, 19893.6884702967, 19735.228083924965, 19579.449408959434, 19426.307061337488, 19275.75642505572, 19127.75363917163, 18982.255585025374, 18839.21987367762, 18698.604833560188, 18560.369498335524, 18424.473594961688, 18290.8775319594, 18159.542387877547, 18030.429899953888, 17903.502452967794, 17778.72306828147, 17656.055393066767, 17535.463689714226, 17416.91282542143, 17300.368261957497, 17185.79604560085, 17073.162797247234, 16962.43570268515, 16853.58250303587, 16746.571485355227, 16641.3714733945, 16537.951818517602, 16436.282390771994, 16336.333570110739, 16238.07623776309, 16141.481767751096, 16046.522018549864, 15953.169324888799, 15861.39648969179, 15771.176776153636, 15682.483899950656, 15595.292021583089, 15509.57573884711, 15425.310079434206, 15342.47049365588, 15261.032847291333, 15180.97341455637, 15102.268871191143, 15024.89628766495, 14948.833122496044, 14874.057215684436, 14800.546782255886, 14728.280405915148, 14657.237032806595, 14587.395965380458, 14518.736856362895, 14451.239702828048, 14384.884840370465, 14319.65293737614, 14255.524989390506, 14192.482313581715, 14130.50654329767, 14069.579622715119, 14009.683801579371, 13950.801630032915, 13892.91595353171, 13836.009907847416, 13780.066914154188, 13725.070674198694, 13671.005165551811, 13617.854636940729, 13565.60360365999, 13514.236843060233, 13463.739390113304, 13414.096533052361, 13365.293809085786, 13317.317000183693, 13270.152128935639, 13223.78545447851, 13178.203468493304, 13133.392891269667, 13089.340667837003, 13046.033964161103, 13003.4601634051, 12961.606862253744, 12920.461867299813, 12880.013191491802, 12840.249050641558, 12801.157859991197, 12762.728230837987, 12724.948967216416, 12687.809062636401, 12651.297696876678, 12615.404232832474, 12580.11821341655, 12545.42935851263, 12511.327561980464, 12477.802888711507, 12444.845571734459, 12412.446009369807, 12380.5947624325, 12349.282551481927, 12318.500254118517, 12288.238902326042, 12258.489679858896, 12229.243919673594, 12200.49310140374, 12172.22884887776, 12144.442927678574, 12117.127242744635, 12090.273836011527, 12063.8748840935, 12037.922696004216, 12012.40971091609, 11987.328495957529, 11962.671744047493, 11938.432271766645, 11914.603017264559, 11891.17703820236, 11868.147509730152, 11845.507722498682, 11823.251080704667, 11801.371100169228, 11779.86140644873, 11758.715732977762, 11737.927919243375, 11717.491908990352, 11697.401748456792, 11677.651584639529, 11658.235663588974, 11639.148328732752, 11620.384019227742, 11601.937268340003, 11583.802701852106, 11565.975036497442, 11548.449078420985, 11531.219721666144, 11514.28194668724, 11497.630818887064, 11481.261487179314, 11465.169182575228, 11449.349216794275, 11433.796980898227, 11418.507943948436, 11403.477651685786, 11388.701725233022, 11374.17585981902, 11359.895823524628, 11345.857456049784, 11332.056667501427, 11318.489437201993, 11305.151812518052, 11292.039907708715, 11279.149902793624, 11266.478042440009, 11254.020634868659, 11241.774050778347, 11229.734722288478, 11217.899141899663, 11206.263861471818, 11194.825491219615, 11183.58069872492, 11172.52620796591, 11161.658798362678, 11150.975303838935, 11140.472611899622, 11130.147662724154, 11119.997448274924, 11110.019011420998, 11100.209445076574, 11090.565891354063, 11081.085540731441, 11071.765631233775, 11062.603447628522, 11053.596320634511, 11044.741626144265, 11036.036784459497, 11027.479259539581, 11019.066558262664, 11010.796229699365, 11002.66586439872, 10994.6730936862, 10986.815588973666, 10979.091061080926, 10971.497259568832, 10964.031972083665, 10956.693023712538, 10949.478276349839, 10942.385628074248, 
10935.413012536414, 10928.558398356956, 10921.819788534609, 10915.195219864472, 10908.682762366014, 10902.28051872081, 10895.986623719811, 10889.799243719897, 10883.716576109702, 10877.736848784416, 10871.85831962954, 10866.079276013326, 10860.398034287824, 10854.812939298363, 10849.322363901372, 10843.924708490315, 10838.618400529662, 10833.401894096754, 10828.27366943144, 10823.232232493285, 10818.27611452631, 10813.403871631108, 10808.614084344157, 10803.905357224297, 10799.276318446162, 10794.72561940056, 10790.251934301526, 10785.8539598001, 10781.5304146046, 10777.280039107356, 10773.101595017717, 10768.993865001285, 10764.955652325294, 10760.985780509935, 10757.083092985598, 10753.246452755944, 10749.474742066628, 10745.766862079687, 10742.121732553365, 10738.538291527459, 10735.015495013871, 10731.5523166925, 10728.147747612196, 10724.800795896868, 10721.510486456464, 10718.27586070291, 10715.095976270859, 10711.96990674311, 10708.896741380722, 10705.875584857706, 10702.90555700014, 10699.98579252977, 10697.115440811933, 10694.2936656077, 10691.51964483027, 10688.792570305477, 10686.11164753632, 10683.476095471506, 10680.885146277886, 10678.33804511679, 10675.834049924082, 10673.37243119398, 10670.952471766528, 10668.573466618662, 10666.2347226588, 10663.935558524938, 10661.675304386119, 10659.453301747302, 10657.26890325753, 10655.121472521309, 10653.010383913203, 10650.935022395592, 10648.894783339467, 10646.889072348282, 10644.917305084786, 10642.978907100798, 10641.07331366982, 10639.19996962254, 10637.358329185074, 10635.547855819961, 10633.768022069871, 10632.018309403904, 10630.298208066555, 10628.607216929177, 10626.944843344012, 10625.310603000627, 10623.704019784855, 10622.124625640068, 10620.571960430803, 10619.045571808727, 10617.545015080854, 10616.069853079956, 10614.619656037243, 10613.194001457143, 10611.79247399418, 10610.414665332019, 10609.060174064469, 10607.728605578573, 10606.419571939605, 10605.132691778075, 10603.867590178628, 10602.623898570797, 10601.401254621622, 10600.199302130126, 10599.017690923494, 10597.85607675509, 10596.71412120414, 10595.591491577155, 10594.487860811003, 10593.402907377611, 10592.336315190307, 10591.287773511722, 10590.256976863267, 10589.243624936133, 10588.247422503799, 10587.26807933603, 10586.305310114305, 10585.358834348708, 10584.428376296211, 10583.513664880333, 10582.61443361216, 10581.730420512731, 10580.861368036678, 10580.007022997226, 10579.167136492426, 10578.34146383261, 10577.529764469145, 10576.731801924323, 10575.947343722484, 10575.176161322273, 10574.41803005007, 10573.67272903453, 10572.94004114223, 10572.219752914421, 10571.511654504822, 10570.815539618507, 10570.131205451773, 10569.458452633102, 10568.797085165024, 10568.146910367048, 10567.507738819531, 10566.879384308464, 10566.261663771256, 10565.654397243376, 10565.057407805918, 10564.470521534102, 10563.89356744654, 10563.326377455473, 10562.768786317774, 10562.220631586835, 10561.681753565188, 10561.15199525804, 10560.631202327488, 10560.119223047588, 10559.615908260126, 10559.12111133118, 10558.634688108388, 10558.156496878966, 10557.686398328398, 10557.224255499881, 10556.769933754396, 10556.323300731494, 10555.884226310738, 10555.452582573782, 10555.028243767116, 10554.611086265439, 10554.200988535602, 10553.79783110125, 10553.401496507973, 10553.011869289126, 10552.628835932157, 10552.252284845545, 10551.882106326304, 10551.518192528001, 10551.160437429351, 10550.808736803334, 10550.462988186804, 10550.123090850666, 10549.788945770513, 10549.460455597795, 10549.137524631415, 10548.820058789912, 10548.507965583996, 10548.201154089622, 10547.899534921522, 10547.603020207123, 10547.311523560975, 10547.024960059582, 10546.743246216643, 10546.466299958749, 10546.194040601458, 10545.926388825803, 10545.66326665517, 10545.404597432587, 10545.150305798381, 10544.900317668253, 10544.654560211653, 10544.412961830589, 10544.175452138752, 10543.941961941044, 10543.712423213368, 10543.486769082845, 10543.26493380832, 10543.046852761217, 10542.832462406703, 10542.62170028517, 10542.414504994056, 10542.210816169953, 10542.010574471007, 10541.81372155964, 10541.62020008556, 10541.42995366903, 10541.242926884473, 10541.059065244315, 10540.878315183068, 10540.700624041805, 10540.525940052758, 10540.354212324248, 10540.18539082586, 10540.019426373898, 10539.856270616992, 10539.695876022075, 10539.538195860494, 10539.38318419442, 10539.23079586344, 10539.080986471443, 10538.933712373624, 10538.788930663824, 10538.64659916201, 10538.506676401967, 10538.369121619253, 10538.233894739296, 10538.100956365735, 10537.97026776892, 10537.841790874663, 10537.715488253103, 10537.591323107858, 10537.469259265243, 
10537.349261163765, 10537.231293843772, 10537.11532293723, 10537.001314657762, 10536.889235790746, 10536.779053683695, 10536.670736236705, 10536.564251893116, 10536.459569630322, 10536.356658950725, 10536.255489872863, 10536.156032922654, 10536.05825912484, 10535.962139994512, 10535.867647528825, 10535.774754198857, 10535.683432941554, 10535.59365715188, 10535.505400675045, 10535.418637798884, 10535.333343246388, 10535.249492168306, 10535.167060135951, 10535.08602313402, 10535.006357553662, 10534.928040185567, 10534.851048213197, 10534.775359206165, 10534.700951113671, 10534.62780225811, 10534.555891328724, 10534.485197375412, 10534.415699802628, 10534.347378363373, 10534.280213153303, 10534.214184604914, 10534.149273481864, 10534.08546087336, 10534.022728188638, 10533.961057151551, 10533.90042979528, 10533.840828457025, 10533.782235772935, 10533.724634673, 10533.668008376106, 10533.612340385132, 10533.557614482143, 10533.50381472367, 10533.450925436064, 10533.39893121093, 10533.347816900643, 10533.29756761392, 10533.2481687115, 10533.199605801863, 10533.15186473705, 10533.104931608534, 10533.058792743166, 10533.0134346992, 10532.968844262366, 10532.925008442036, 10532.881914467427, 10532.839549783872, 10532.797902049186, 10532.756959130053, 10532.716709098488, 10532.677140228387, 10532.638240992084, 10532.600000056995, 10532.562406282326, 10532.5254487158


[STATUS] Please select an option
[1] Make a prediction
[2] Close
>>> 1
[SETTINGS] New example (x1 x2 ... xd): 1950
[WARNING] The expected value of y is: [294.69949273]